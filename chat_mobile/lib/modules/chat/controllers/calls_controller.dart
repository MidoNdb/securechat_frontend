import 'dart:async';
import 'package:flutter/material.dart';
import 'package:get/get.dart' hide navigator;
import 'package:flutter_webrtc/flutter_webrtc.dart';

import '../../../data/services/websocket_service.dart';
import '../../../data/services/webrtc_service.dart';

class CallsController extends GetxController {
  RTCPeerConnection? peerConnection;
  final WebSocketService _wsService = Get.find<WebSocketService>();
  final WebRTCService _webRTCService = WebRTCService();

  MediaStream? localStream;
  final RTCVideoRenderer localRenderer = RTCVideoRenderer();
  final RTCVideoRenderer remoteRenderer = RTCVideoRenderer();

  final isVideoEnabled = true.obs;
  final isMicEnabled = true.obs;
  final isCallActive = false.obs;
  final isRemoteVideoAvailable = false.obs;
  final callStatus = "Initialisation...".obs;
  final isRinging = false.obs;

  String targetUserId = "";
  String? pendingRemoteSdp;
  String? currentConversationId;
  String callType = "VIDEO"; // Par d√©faut
  
  final List<RTCIceCandidate> _iceCandidatesQueue = [];
  StreamSubscription? _wsSubscription;

  @override
  void onInit() {
    super.onInit();
    _initRenderers();
    _setupWebSocketListener();
    _loadArguments();
  }

  Future<void> _initRenderers() async {
    await localRenderer.initialize();
    await remoteRenderer.initialize();
  }
void _loadArguments() {
  if (Get.arguments != null) {
    // On utilise les cl√©s d√©finies dans MainShellController
    targetUserId = Get.arguments['targetId']?.toString() ?? "";
    currentConversationId = Get.arguments['conversationId']?.toString();
    
    // Harmonisation du type d'appel
    callType = Get.arguments['callType']?.toString().toUpperCase() ?? "VIDEO";
    
    if (Get.arguments['isCaller'] == true) {
      initCall(true);
    } else {
      // ‚úÖ MODIFICATION : Utiliser 'remoteSdp' au lieu de 'sdp'
      pendingRemoteSdp = Get.arguments['remoteSdp']; 
      isRinging.value = true;
      callStatus.value = "Appel entrant...";
      
      print("üì• Appel entrant de: $targetUserId avec SDP: ${pendingRemoteSdp != null}");
    }
  }
}
  // void _loadArguments() {
  //   if (Get.arguments != null) {
  //     targetUserId = Get.arguments['targetId']?.toString() ?? "";
  //     currentConversationId = Get.arguments['conversationId']?.toString();
  //     // On r√©cup√®re le type d'appel depuis les arguments (AUDIO ou VIDEO)
  //     callType = Get.arguments['callType']?.toString().toUpperCase() ?? "VIDEO";
      
  //     if (Get.arguments['isCaller'] == true) {
  //       initCall(true);
  //     } else {
  //       pendingRemoteSdp = Get.arguments['sdp'];
  //       isRinging.value = true;
  //       callStatus.value = "Appel entrant...";
  //     }
  //   }
  // }
void _setupWebSocketListener() {
  _wsSubscription = _wsService.messageStream.listen((data) {
    final String type = data['type'] ?? '';
    final payload = data['data'] ?? {};

    switch (type) {
      // On ignore 'incoming_call' ici car MainShell l'a d√©j√† trait√©
      case 'call_accepted':
        _handleAnswer(payload['sdp']);
        break;
      case 'ice_candidate':
        _handleIceCandidate(payload);
        break;
      case 'call_rejected':
      case 'call_ended':
        _cleanupCall();
        if (Get.isDialogOpen ?? false) Get.back();
        Get.back();
        break;
    }
  });
}
// void _setupWebSocketListener() {
//   _wsSubscription = _wsService.messageStream.listen((data) {
//     final String type = data['type'] ?? '';
//     final payload = data['data'] ?? {};

//     print('üì© Signal WebRTC re√ßu: $type'); // ‚Üê DEBUG

//     switch (type) {
//       // ‚úÖ AJOUT CRITIQUE : G√©rer l'appel entrant
//       case 'incoming_call':
//         print('üìû Appel entrant d√©tect√© !');
//         _handleIncomingCall(payload);
//         break;
        
//       case 'call_accepted':
//         _handleAnswer(payload['sdp']);
//         break;
        
//       case 'ice_candidate':
//         _handleIceCandidate(payload);
//         break;
        
//       case 'call_rejected':
//       case 'call_ended':
//         _cleanupCall();
//         if (Get.currentRoute.contains('CALLS')) Get.back();
//         break;
//     }
//   });
// }

// ‚úÖ NOUVELLE M√âTHODE : G√©rer l'appel entrant
void _handleIncomingCall(Map<String, dynamic> payload) {
  print('üìû === APPEL ENTRANT ===');
  print('   SDP: ${payload['sdp']?.substring(0, 50) ?? "null"}...');
  print('   Call Type: ${payload['call_type']}');
  
  // Stocker le SDP distant
  pendingRemoteSdp = payload['sdp'];
  
  // D√©finir le type d'appel (AUDIO ou VIDEO)
  callType = (payload['call_type'] ?? 'VIDEO').toString().toUpperCase();
  
  // Activer le mode sonnerie
  isRinging.value = true;
  callStatus.value = "Appel entrant...";
  
  print('‚úÖ Appel entrant configur√©');
}

  // --- LOGIQUE CORE WEBRTC ---
  Future<void> initCall(bool isCaller) async {
  try {
    // 1. R√âCUP√âRATION ET NORMALISATION DES ARGUMENTS
    // On v√©rifie si les arguments existent, sinon on utilise les valeurs par d√©faut
    final args = Get.arguments ?? {};
    
    // On r√©cup√®re le type d'appel (VIDEO ou AUDIO)
    final String rawType = (args['callType'] ?? callType).toString().toUpperCase();
    callType = rawType;
    
    // D√©terminer si on doit activer la cam√©ra
    bool wantVideo = (callType == "VIDEO"); 
    isVideoEnabled.value = wantVideo;

    print("üìû === INITIALISATION APPEL ===");
    print("   Type: $callType | Vid√©o: $wantVideo | Est l'appelant: $isCaller");

    // 2. CONFIGURATION AUDIO
    // Active le haut-parleur automatiquement pour la vid√©o, sinon reste sur l'√©couteur
    await Helper.setSpeakerphoneOn(wantVideo);
    
    isRinging.value = false;
    isCallActive.value = true;
    callStatus.value = isCaller ? "Appel en cours..." : "Connexion...";

    // 3. R√âCUP√âRATION DU STREAM LOCAL (Micro + Cam√©ra si besoin)
    localStream = await _webRTCService.getUserMedia(hasVideo: wantVideo);
    
    // Attacher le flux √† l'aper√ßu local
    if (wantVideo) {
      localRenderer.srcObject = localStream;
      print("‚úÖ Stream local attach√© au renderer vid√©o");
    } else {
      localRenderer.srcObject = null;
      print("‚úÖ Mode audio uniquement (pas de cam√©ra)");
    }

    // 4. CR√âATION DE LA PEERCONNECTION
    peerConnection = await _webRTCService.createPeerConnectionInstance(
      localStream: localStream,
      onRemoteStream: (stream) {
        print("üì• Flux distant re√ßu !");
        
        // Attacher le flux distant au renderer
        remoteRenderer.srcObject = stream;
        
        // Activer les pistes audio distantes pour entendre l'interlocuteur
        for (var track in stream.getAudioTracks()) {
          track.enabled = true;
          print("üîä Piste audio distante activ√©e: ${track.id}");
        }
        
        // Afficher la vid√©o distante si c'est un appel vid√©o
        isRemoteVideoAvailable.value = wantVideo;
        print("‚úÖ Stream distant configur√© (Audio: ${stream.getAudioTracks().length})");
      },
      onIceCandidate: (candidate) {
        print("üßä ICE Candidate g√©n√©r√©, envoi au serveur...");
        _sendSignaling('ice_candidate', {
          'candidate': candidate.candidate,
          'sdpMid': candidate.sdpMid,
          'sdpMLineIndex': candidate.sdpMLineIndex,
        });
      },
    );

    // 5. N√âGOCIATION SDP (OFFER / ANSWER)
    if (isCaller) {
      // --- CAS APPELANT ---
      print("üì§ Cr√©ation de l'offre SDP...");
      final offer = await _webRTCService.createOffer(
        peerConnection!,
        hasVideo: wantVideo,
      );
      
      _sendSignaling('call_offer', {
        'sdp': offer.sdp,
        'call_type': callType,
      });
      print("‚úÖ Offre envoy√©e avec succ√®s");

    } else {
      // --- CAS DESTINATAIRE (R√âPONDEUR) ---
      // On r√©cup√®re le SDP de l'offre envoy√© par le MainShellController
      final String? sdpToUse = args['remoteSdp'] ?? pendingRemoteSdp;

      if (sdpToUse != null) {
        print("üì• Application de l'offre distante...");
        await peerConnection!.setRemoteDescription(
          RTCSessionDescription(sdpToUse, 'offer')
        );
        
        print("üìù Cr√©ation de la r√©ponse (Answer)...");
        final answer = await _webRTCService.createAnswer(peerConnection!);
        
        _sendSignaling('call_accepted', {
          'sdp': answer.sdp
        });
        
        // Une fois la connexion √©tablie, on traite les candidats ICE qui √©taient en attente
        _processQueuedCandidates();
        
        callStatus.value = "En communication";
        print("‚úÖ R√©ponse envoy√©e, appel connect√©");
      } else {
        throw "Erreur : Aucun SDP distant (offre) n'a √©t√© trouv√©.";
      }
    }
    
    print("üìû === APPEL INITIALIS√â AVEC SUCC√àS ===");
    
  } catch (e, stackTrace) {
    print("‚ùå Erreur CRITIQUE initCall: $e");
    print(stackTrace);
    callStatus.value = "Erreur de connexion";
    _cleanupCall();
  }
}

  void _handleAnswer(String sdp) async {
    if (peerConnection != null) {
      final remoteDesc = await peerConnection!.getRemoteDescription();
      if (remoteDesc == null) {
        await peerConnection!.setRemoteDescription(
          RTCSessionDescription(sdp, 'answer')
        );
        _processQueuedCandidates();
        callStatus.value = "En cours";
      }
    }
  }

  void _handleIceCandidate(Map<String, dynamic> payload) async {
    final candidate = RTCIceCandidate(
      payload['candidate'], 
      payload['sdpMid'], 
      payload['sdpMLineIndex']
    );

    if (peerConnection != null && (await peerConnection!.getRemoteDescription()) != null) {
      await peerConnection!.addCandidate(candidate);
    } else {
      _iceCandidatesQueue.add(candidate);
    }
  }

  void _processQueuedCandidates() async {
    for (var cand in _iceCandidatesQueue) {
      await peerConnection!.addCandidate(cand);
    }
    _iceCandidatesQueue.clear();
  }

  void _sendSignaling(String type, Map<String, dynamic> data) {
    if (currentConversationId == null) return;
    _wsService.sendCallSignal(
      targetId: targetUserId,
      conversationId: currentConversationId!,
      action: type,
      extraData: data,
    );
  }

  // --- ACTIONS ---

  Future<void> acceptCall() async {
    await initCall(false);
  }

  void rejectCall() {
    _sendSignaling('call_rejected', {});
    _cleanupCall();
    Get.back();
  }

  void endCall() {
    _sendSignaling('call_ended', {});
    _cleanupCall();
    Get.back();
  }

  void toggleMic() {
    if (localStream != null) {
      isMicEnabled.value = !isMicEnabled.value;
      localStream!.getAudioTracks().forEach((t) => t.enabled = isMicEnabled.value);
    }
  }

  void toggleVideo() {
    if (localStream != null && callType == "VIDEO") {
      isVideoEnabled.value = !isVideoEnabled.value;
      localStream!.getVideoTracks().forEach((t) => t.enabled = isVideoEnabled.value);
    }
  }

  Future<void> switchCamera() async {
    if (localStream != null && isVideoEnabled.value) {
      final videoTrack = localStream!.getVideoTracks().first;
      await Helper.switchCamera(videoTrack);
    }
  }

  Future<void> _cleanupCall() async {
    isCallActive.value = false;
    isRinging.value = false;
    
    localStream?.getTracks().forEach((t) => t.stop());
    localStream?.dispose();
    localStream = null;

    await peerConnection?.close();
    await peerConnection?.dispose();
    peerConnection = null;
    
    localRenderer.srcObject = null;
    remoteRenderer.srcObject = null;
    _iceCandidatesQueue.clear();
  }

  @override
  void onClose() {
    _wsSubscription?.cancel();
    _cleanupCall();
    localRenderer.dispose();
    remoteRenderer.dispose();
    super.onClose();
  }
} 